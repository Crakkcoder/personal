{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObaxlJyOx2ueRAsIeVG3Up"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YpvRRd-hUbJb"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# Step 1: Send HTTP request to the GeeksforGeeks job search page\n","url = \"https://www.geeksforgeeks.org/jobs/\"  # URL for GeeksforGeeks job portal\n","response = requests.get(url)\n","\n","# Step 2: Parse the HTML content\n","soup = BeautifulSoup(response.text, 'html.parser')\n","\n","# Step 3: Find the job listings on the page\n","# In this example, let's say job listings are inside <div> tags with the class \"job-listing\"\n","job_listings = soup.find_all('div', class_='job-listing')\n","\n","# Step 4: Extract relevant job details from each job listing\n","jobs = []\n","for job in job_listings:\n","    job_title = job.find('h3').get_text(strip=True) if job.find('h3') else None\n","    company_name = job.find('span', class_='company-name').get_text(strip=True) if job.find('span', class_='company-name') else None\n","    location = job.find('span', class_='location').get_text(strip=True) if job.find('span', class_='location') else None\n","    job_link = job.find('a')['href'] if job.find('a') else None\n","\n","    # Add job details to the jobs list\n","    jobs.append({\n","        'Job Title': job_title,\n","        'Company': company_name,\n","        'Location': location,\n","        'Job Link': job_link\n","    })\n","\n","# Step 5: Convert the extracted data to a pandas DataFrame for easy analysis\n","df_jobs = pd.DataFrame(jobs)\n","\n","# Step 6: Display the job listings\n","print(df_jobs.head())\n"]}]}