{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhiGwp5SdwTNOAL1rlXk5v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qkfURxuvPZSS","executionInfo":{"status":"ok","timestamp":1732855630068,"user_tz":-330,"elapsed":1246,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}},"outputId":"1322ccb2-575f-4cd3-dff3-e6748e92d189"},"outputs":[{"output_type":"stream","name":"stdout","text":["Quotes have been successfully scraped and saved.\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","# Step 1: Request the webpage\n","url = 'https://quotes.toscrape.com/'  # Replace with the actual URL from where you want to scrape\n","response = requests.get(url)\n","\n","# Step 2: Parse the HTML content of the page\n","soup = BeautifulSoup(response.text, 'html.parser')\n","\n","# Step 3: Extract the quotes and authors\n","quotes = soup.find_all('span', class_='text')  # Quotes are typically inside <span class=\"text\">\n","authors = soup.find_all('small', class_='author')  # Authors are inside <small class=\"author\">\n","\n","# Step 4: Write the data to a CSV file\n","with open('quotes.csv', mode='w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","    writer.writerow(['Quote', 'Author'])  # Writing headers\n","\n","    # Step 5: Loop through the quotes and authors and save to the CSV\n","    for quote, author in zip(quotes, authors):\n","        writer.writerow([quote.text.strip(), author.text.strip()])\n","\n","print(\"Quotes have been successfully scraped and saved.\")\n"]},{"cell_type":"code","source":["for page_number in range(1, 6):  # Scrape the first 5 pages\n","    url = f'https://quotes.toscrape.com/page/{page_number}/'\n","    response = requests.get(url)\n","    soup = BeautifulSoup(response.text, 'html.parser')\n","\n","    # Extract quotes and authors, and write to CSV as shown in the previous code...\n"],"metadata":{"id":"c4Rmkqr1Pn6q","executionInfo":{"status":"ok","timestamp":1732855633341,"user_tz":-330,"elapsed":1027,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from selenium import webdriver\n","from bs4 import BeautifulSoup\n","\n","# Set up the driver\n","driver = webdriver.Chrome()\n","\n","# Navigate to the webpage\n","driver.get('https://quotes.toscrape.com/')\n","\n","# Wait for the page to load fully (optional, depending on the website)\n","driver.implicitly_wait(5)\n","\n","# Extract page content after JavaScript has executed\n","soup = BeautifulSoup(driver.page_source, 'html.parser')\n","\n","# Now you can scrape the quotes using BeautifulSoup as usual\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"id":"uScSSr43Prvz","executionInfo":{"status":"error","timestamp":1732855696217,"user_tz":-330,"elapsed":410,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}},"outputId":"a0587693-4f9e-42dd-98d2-5489966d812a"},"execution_count":4,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'selenium'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-718aa5838d65>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Set up the driver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}]}